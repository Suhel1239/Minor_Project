{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ArUDc-K4j829","executionInfo":{"status":"ok","timestamp":1730802860086,"user_tz":-330,"elapsed":15560,"user":{"displayName":"Suhel Khan","userId":"13518959234566628578"}},"outputId":"5726318a-2223-44f1-c1a2-287ea3c5ba16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.27-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.10-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.27-py3-none-any.whl (878 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.10-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.27 ultralytics-thop-2.0.10\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzpoMZhXkeYY","executionInfo":{"status":"ok","timestamp":1730802883970,"user_tz":-330,"elapsed":23888,"user":{"displayName":"Suhel Khan","userId":"13518959234566628578"}},"outputId":"6a064223-56c3-4b2c-b356-c1961a66b0b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"7gpkz1j0jmbD"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","# Load a model\n","model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n","\n","# Train the model\n","results = model.train(data=\"/content/drive/MyDrive/project8/wound.yaml\", epochs=100, imgsz=640 ,\n","                      project=\"/content/drive/MyDrive/project8/model_results\")"]},{"cell_type":"code","source":["from ultralytics import YOLO\n","import torch\n","import os\n","import json\n","from PIL import Image , ImageDraw\n","import numpy as np\n","import cv2\n","\n","\n","# Load YOLOv8 models with pretrained weights\n","model_a = YOLO(\"/content/drive/MyDrive/project8/model_results/train3/weights/last.pt\")  # initial detection\n","model_b = YOLO(\"/content/drive/MyDrive/project8/lastsegcategory.pt\")  # Second model for segmentation\n","\n","input_dir = \"/content/drive/MyDrive/project8/model_results/input_test\"\n","output_dir = \"/content/drive/MyDrive/project8/model_results/output_test\"\n","os.makedirs(output_dir, exist_ok=True)  # Ensure output directory exists\n","\n","def pipeline_yolo_models(input_dir):\n","    for image_name in os.listdir(input_dir):\n","        image_path = os.path.join(input_dir, image_name)\n","\n","        # Ensure the file is an image\n","        if image_path.lower().endswith(('.jpg', '.jpeg', '.png')):\n","            # Step 1: Load the original image\n","            original_image = cv2.imread(image_path)\n","\n","            # Step 2: Run Model A for initial detections\n","            results_a = model_a.predict(source=image_path, save=False)\n","\n","            # Optionally save the Model A output image with detections drawn\n","            model_a_output_path = os.path.join(output_dir, f\"detected_{image_name}\")\n","            results_a[0].plot()  # Generate a plot of the results\n","            results_a[0].save(model_a_output_path)  # Save the output image with detections\n","\n","            # Step 3: Run Model B on the output of Model A (saved image)\n","            results_b = model_b.predict(source=model_a_output_path, save=False)  # Don't save automatically\n","\n","            # Optionally save the final output image from Model B\n","            model_b_output_path = os.path.join(output_dir, f\"segmented_{image_name}\")\n","            results_b[0].save(model_b_output_path)  # Save the output image from Model B\n","\n","            # print(f\"Saved detection output for {image_name} at {model_a_output_path}\")\n","            # print(f\"Saved segmentation output for {image_name} at {model_b_output_path}\")\n","            os.remove(model_a_output_path)\n","\n","# Run the pipeline\n","pipeline_yolo_models(input_dir)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"WgM3Tgqchrqo","executionInfo":{"status":"ok","timestamp":1730803889847,"user_tz":-330,"elapsed":9275,"user":{"displayName":"21BCS019_Mohammad Asad Ali","userId":"01214873993479601355"}},"outputId":"5ea705a0-9bc0-4e89-a866-88534eb3a220"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/cut (20).jpg: 640x640 3 Cutss, 8.8ms\n","Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_cut (20).jpg: 640x640 1 acute, 20.8ms\n","Speed: 1.6ms preprocess, 20.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/burns (16).jpg: 640x640 4 Burnss, 8.4ms\n","Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_burns (16).jpg: 640x640 (no detections), 20.8ms\n","Speed: 2.0ms preprocess, 20.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/burns (2).jpg: 640x640 1 Burns, 7.5ms\n","Speed: 1.9ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_burns (2).jpg: 640x640 1 chronic, 20.9ms\n","Speed: 2.1ms preprocess, 20.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/cut (15).jpg: 640x640 1 Cuts, 7.4ms\n","Speed: 1.6ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_cut (15).jpg: 640x640 2 acutes, 20.9ms\n","Speed: 1.9ms preprocess, 20.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/burns (22).jpg: 640x640 1 Burns, 7.5ms\n","Speed: 2.1ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_burns (22).jpg: 640x640 1 chronic, 20.8ms\n","Speed: 1.4ms preprocess, 20.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/bruises (27).jpg: 640x640 1 Bruises, 7.4ms\n","Speed: 1.8ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_bruises (27).jpg: 640x640 (no detections), 20.8ms\n","Speed: 1.4ms preprocess, 20.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/bruises (29).jpg: 640x640 1 Bruises, 7.4ms\n","Speed: 1.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_bruises (29).jpg: 640x640 (no detections), 20.9ms\n","Speed: 1.9ms preprocess, 20.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/mirrored_cut (50).jpg: 640x640 1 Cuts, 1 Diabetic, 7.8ms\n","Speed: 2.0ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_mirrored_cut (50).jpg: 640x640 1 acute, 20.8ms\n","Speed: 1.4ms preprocess, 20.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/mirrored_burns (20).jpg: 640x640 3 Burnss, 7.4ms\n","Speed: 1.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_mirrored_burns (20).jpg: 640x640 (no detections), 20.9ms\n","Speed: 1.5ms preprocess, 20.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/mirrored_burns (1).jpg: 640x640 6 Burnss, 7.5ms\n","Speed: 1.7ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_mirrored_burns (1).jpg: 640x640 (no detections), 20.9ms\n","Speed: 1.4ms preprocess, 20.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/mirrored_bruises (63).jpg: 640x640 1 Bruises, 7.5ms\n","Speed: 1.7ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_mirrored_bruises (63).jpg: 640x640 1 acute, 20.8ms\n","Speed: 1.4ms preprocess, 20.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/mirrored_bruises (68).jpg: 640x640 7 Bruisess, 9.3ms\n","Speed: 2.2ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_mirrored_bruises (68).jpg: 640x640 1 necrotic, 20.8ms\n","Speed: 2.0ms preprocess, 20.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/0402.jpg: 640x640 1 Diabetic, 12.0ms\n","Speed: 2.2ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_0402.jpg: 640x640 1 acute, 20.9ms\n","Speed: 1.9ms preprocess, 20.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/0431.jpg: 640x640 1 Diabetic, 9.4ms\n","Speed: 2.2ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_0431.jpg: 640x640 1 acute, 20.9ms\n","Speed: 2.7ms preprocess, 20.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/0377.jpg: 640x640 1 Diabetic, 10.0ms\n","Speed: 2.4ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_0377.jpg: 640x640 1 acute, 20.9ms\n","Speed: 2.0ms preprocess, 20.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/0392.jpg: 640x640 1 Diabetic, 10.2ms\n","Speed: 2.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_0392.jpg: 640x640 1 chronic, 20.8ms\n","Speed: 1.9ms preprocess, 20.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/mirrored_cut (38).jpg: 640x640 1 Cuts, 7.6ms\n","Speed: 1.7ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_mirrored_cut (38).jpg: 640x640 1 acute, 20.8ms\n","Speed: 1.3ms preprocess, 20.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/bruises (48).jpg: 640x640 1 Bruises, 7.4ms\n","Speed: 1.6ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_bruises (48).jpg: 640x640 (no detections), 20.8ms\n","Speed: 1.3ms preprocess, 20.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/0702.jpg: 640x640 1 Diabetic, 9.5ms\n","Speed: 2.0ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_0702.jpg: 640x640 1 acute, 20.8ms\n","Speed: 1.6ms preprocess, 20.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/input_test/mirrored_cut (21).jpg: 640x640 1 Cuts, 7.4ms\n","Speed: 1.6ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","image 1/1 /content/drive/MyDrive/project8/model_results/output_test/detected_mirrored_cut (21).jpg: 640x640 (no detections), 20.8ms\n","Speed: 1.4ms preprocess, 20.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","import cv2\n","import os\n","\n","# Load YOLOv8 models with pretrained weights\n","model_a = YOLO(\"/content/drive/MyDrive/project8/model_results/train3/weights/last.pt\")  # initial detection\n","model_b = YOLO(\"/content/drive/MyDrive/project8/lastsegcategory.pt\")  # Second model for segmentation\n","\n","output_dir = \"/content/drive/MyDrive/project8/model_results/output_test\"\n","os.makedirs(output_dir, exist_ok=True)  # Ensure output directory exists\n","\n","def pipeline_yolo_camera():\n","    # Open the default camera (index 0)\n","    cap = cv2.VideoCapture(0)\n","\n","    if not cap.isOpened():\n","        print(\"Error: Could not open camera.\")\n","        return\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            print(\"Error: Failed to capture image.\")\n","            break\n","\n","        # Step 1: Run Model A for initial detections\n","        results_a = model_a.predict(source=frame, save=False)\n","\n","        # Draw the Model A results on the frame\n","        frame_with_detections = results_a[0].plot()  # Annotate frame with detection results\n","\n","        # Step 2: Run Model B for segmentation on Model A's output\n","        results_b = model_b.predict(source=frame, save=False)\n","\n","        # Draw the Model B results (segmentation) on the frame\n","        frame_with_segmentation = results_b[0].plot()\n","\n","        # Display the final output\n","        cv2.imshow(\"YOLO Detection and Segmentation\", frame_with_segmentation)\n","\n","        # Press 'q' to exit the loop\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","    # Release the capture and close any OpenCV windows\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","# Run the pipeline\n","pipeline_yolo_camera()"],"metadata":{"id":"wMXcur8W37bp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730802910370,"user_tz":-330,"elapsed":20323,"user":{"displayName":"Suhel Khan","userId":"13518959234566628578"}},"outputId":"65b9d64c-79cc-46b8-f882-eee849d02b17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Error: Could not open camera.\n"]}]}]}